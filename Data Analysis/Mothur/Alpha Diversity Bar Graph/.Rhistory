return(temp/(length(x)-1))
}
NewVariance(Q1$Observations)
NewVariance = function(x)
{
tempMean = mean(x)
for(j in length(x))
{
temp = (x[j]- tempMean)^2 + temp
}
return(temp/(length(x)-1))
}
NewVariance(Q1$Observations)
var(Q1$Observations)
NewVariance = function(x)
{
tempMean = mean(x)
for(j in length(x))
{
temp = (x[j]- tempMean)^2 + temp
}
return(temp/(length(x)))
}
NewVariance(Q1$Observations)
NewVariance = function(x)
{
tempMean = mean(x)
for(j in length(x))
{
temp = (x[j]- tempMean)^2 + temp
}
return(temp/(length(x)-1))
}
NewVariance(Q1$Observations)
NewVariance = function(x)
{
tempMean = mean(x)
for(j in length(x))
{
temp = (x[j] - tempMean) * (x[j] - tempMean) + temp
}
return(temp/(length(x)-1))
}
NewVariance(Q1$Observations)
newlist = Q1$Observations[1:29] - mean(Q1$Observations)
newlist
newlistSq = newlist^2
totalsum = sum(newlistSq)
varsux = totalsum/(length(Q1$Observations)-1)
newlist = Q1$Observations[] - mean(Q1$Observations)
newlist = Q1$Observations[] - mean(Q1$Observations)
rm(newList)
rm(newlist)
newlist = Q1$Observations[] - mean(Q1$Observations)
newlist = (x[] - mean(x))^2
newlist = (x[] - mean(x))
newlist = (Q1$Observations[] - mean(Q1$Observations))^2
NewVariance = function(x)
{
newlist = (x[] - mean(x))^2
return(sum(newlist)/(length(x)-1)
}
NewVariance = function(x)
{
newlist = (x[] - mean(x))^2
return(sum(newlist)/(length(x)-1))
}
NewVariance(Q1$Observations)
var(Q1$Observations)
NewStdDev = function(x)
{
sqrt(var(x))
}
NewStdDev(Q1$Observations)
sd(Q1$Observations)
NewStdErr = function(x)
{
sd(x)/(sqrt(length(x)))
}
NewStdErr(Q1$Observations)
model.lm = lm(y ~ x, data = Q2)
model.log10 = lm(y ~ log10(x), data = Q2)
model.sqrt = lm(y ~ sqrt(x), data = Q2)
model.quad = lm(y ~ x + I(x^2), data = Q2)
model.cube = lm(y ~ x + I(x^2) + I(x^3), data = Q2)
summary(model.lm)
anova(model.lm)
AIC(model.lm)
summary(model.log10)
anova(model.log10)
AIC(model.log10)
summary(model.sqrt)
anova(model.sqrt)
AIC(model.sqrt)
summary(model.quad)
anova(model.quad)
AIC(model.quad)
summary(model.cube)
anova(model.cube)
AIC(model.cube)
summary(model.lm)
summary(model.log10)
summary(model.lm)
summary(model.sqrt)
summary(model.quad)
summary(model.cube)
model.lm = lm(y ~ x, data = Q2)
summary(model.lm)
model.log10 = lm(y ~ log10(x), data = Q2)
summary(model.log10)
anova(model.log10)
summary(model.lm)
anova(model.lm)
library(nortest)
library(EnvStats)
model.lm = lm(y ~ x, data = Q2)
model.log10 = lm(y ~ log10(x), data = Q2)
model.sqrt = lm(y ~ sqrt(x), data = Q2)
model.quad = lm(y ~ x + I(x^2), data = Q2)
model.cube = lm(y ~ x + I(x^2) + I(x^3), data = Q2)
summary(model.lm)
anova(model.lm)
AIC(model.lm)
summary(model.log10)
anova(model.log10)
AIC(model.log10)
summary(model.sqrt)
anova(model.sqrt)
AIC(model.sqrt)
summary(model.quad)
anova(model.quad)
AIC(model.quad)
summary(model.cube)
anova(model.cube)
AIC(model.cube)
rawdata = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 3/ProfileAveraged_SCM_Marshall_Gulch_Data.csv", header = TRUE)
#Downloading and installing new packages
install.packages("EnvStats")
install.packages("EnvStats")
library(EnvStats)
library(ggplot2)
model.lm
#6 lines below create regression models that we will then be looking at
model.lm = lm(percentC ~ Ca, data = rawdata)
model.log10 = lm(percentC ~ log10(Ca), data = rawdata)
model.sqrt = lm(percentC ~ sqrt(Ca), data = rawdata)
model.quad = lm(percentC ~ Ca + I(Ca^2), data = rawdata)
model.cube = lm(percentC ~ Ca + I(Ca^2) + I(Ca^3), data = rawdata)
#Summary created below is to help determine which model to use
summary(model.lm)
anova(model.lm)
AIC(model.lm) #A sort of index that indicates how closely the model matches the data that it was generated from. You want a lower value here
summary(model.log10)
anova(model.log10)
AIC(model.log10)
summary(model.sqrt)
anova(model.sqrt)
AIC(model.sqrt)
model.lm = lm(y ~ x, data = Q2)
summary(model.lm)
model.log10 = lm(y ~ log10(x), data = Q2)
model.sqrt = lm(y ~ sqrt(x), data = Q2)
model.quad = lm(y ~ x + I(x^2), data = Q2)
model.cube = lm(y ~ x + I(x^2) + I(x^3), data = Q2)
summary(model.lm)
anova(model.lm)
AIC(model.lm)
linear = lm(y ~ x, data = Q2)
log = lm(y ~ log10(x), data = Q2)
sqrt = lm(y ~ sqrt(x), data = Q2)
quad = lm(y ~ x + I(x^2), data = Q2)
cube = lm(y ~ x + I(x^2) + I(x^3), data = Q2)
summary(linear)
plot(linear)
plot(log)
plot(sqrt)
plot(cube)
summary(linear)
anova(linear)
AIC(linear)
summary(log)
anova(log)
AIC(log)
summary(sqrt)
anova(sqrt)
AIC(sqrt)
summary(quad)
anova(quad)
AIC(quad)
summary(cube)
anova(cube)
AIC(cube)
plot(linear)
linear = lm(y ~ x, data = Q2)
log = lm(y ~ log10(x), data = Q2)
sqrt = lm(y ~ sqrt(x), data = Q2)
quad = lm(y ~ x + I(x^2), data = Q2)
cube = lm(y ~ x + I(x^2) + I(x^3), data = Q2)
summary(linear)
AIC(linear)
summary(log)
AIC(log)
summary(linear)
summary(log)
summary(sqrt)
summary(quad)
summary(log)
summary(sqrt)
summary(quad)
summary(cube)
AIC(log)
AIC(linear)
summary(linear)
summary(log)
summary(sqrt)
summary(quad)
summary(linear)
AIC(linear)
anova(linear)
plot(linear)
shapiro.test(Q3$Blueberry_pints_acre)
Q3$NitrogenApp_lbs_acre = as.factor(Q3$NitrogenApp_lbs_acre)
Q3$NitrogenApp_lbs_acre = as.factor(Q3$NitrogenApp_lbs_acre)
leveneTest(Blueberry_pints_acre ~ NitrogenApp_lbs_acre,data = Q3)
library(agricolae)
library(car)
library(nortest)
library(EnvStats)
leveneTest(Blueberry_pints_acre ~ NitrogenApp_lbs_acre,data = Q3)
Blueberry.aov = aov(Blueberry_pints_acre ~ NitrogenApp_lbs_acre,data = Q3)
summary(Blueberry.aov)
shapiro.test(resid(Blueberry.aov))
plot(Blueberry.aov)
summary(Blueberry.aov)
#calculate total sums of squares from variance
TotalSS = NewVariance(Q3$Blueberry_pints_acre) * (length(Q3$Blueberry_pints_acre)-1)
TotalSS
var(Q3$Blueberry_pints_acre)
NewVariance(Q3$Blueberry_pints_acre)
TotalSS
#Testing polynomial contrasts
contrasts(Q3$NitrogenApp_lbs_acre) = contr.treatment(levels(Q3$NitrogenApp_lbs_acre))
Q3$NitrogenApp_lbs_acre
Blueberrycontrasts = aov(Blueberry_pints_acre ~ NitrogenApp_lbs_acre, data = Q3)
summary.aov(Blueberrycontrasts)
summary(Blueberry.aov)
WeedData = read.csv(file = "C:/Users/kdph224/Desktop/Graduate School/Courses/Spring 2021/PLS 697/Homework 3/WeedData.csv", header = TRUE)
Q3$NitrogenApp_lbs_acre
#Testing polynomial contrasts
contrasts(Q3$NitrogenApp_lbs_acre) = contr.treatment(levels(Q3$NitrogenApp_lbs_acre))
Q3$NitrogenApp_lbs_acre
#Testing polynomial contrasts
contrasts(Q3$NitrogenApp_lbs_acre) = contr.poly(levels(Q3$NitrogenApp_lbs_acre))
Q3$NitrogenApp_lbs_acre
Blueberrycontrasts = aov(Blueberry_pints_acre ~ NitrogenApp_lbs_acre, data = Q3)
summary.aov(Blueberrycontrasts)
summary(Blueberry.aov)
summary.lm(aov(Q3$Blueberry_pints_acre~Q3$NitrogenApp_lbs_acre))
summary.aov(Blueberrycontrasts)
summary.lm(aov(Q3$Blueberry_pints_acre~Q3$NitrogenApp_lbs_acre))
#pairwise comparison of means
Blueberry.hsd = HSD.test(Blueberry.aov,"NitrogenApp_lbs_acre")
beets.hsd
Blueberry.hsd
shapiro.test(resid(Blueberry.aov))
plot(Blueberry.aov)
contrasts(Q3$NitrogenApp_lbs_acre) = contr.poly(levels(Q3$NitrogenApp_lbs_acre))
Q3$NitrogenApp_lbs_acre
leveneTest(Blueberry_pints_acre ~ NitrogenApp_lbs_acre,data = Q3)
plot(Blueberry.aov)
contrasts(Q3$NitrogenApp_lbs_acre) = contr.poly(levels(Q3$NitrogenApp_lbs_acre))
plot(Blueberry.aov)
contrasts(Q3$NitrogenApp_lbs_acre) = contr.poly(levels(Q3$NitrogenApp_lbs_acre))
Q3$NitrogenApp_lbs_acre
summary.lm(aov(Q3$Blueberry_pints_acre~Q3$NitrogenApp_lbs_acre))
#Testing polynomial contrasts
contrasts(Q3$NitrogenApp_lbs_acre) = contr.poly
Q3$NitrogenApp_lbs_acre
#Testing polynomial contrasts
contrasts(Q3$NitrogenApp_lbs_acre) = contr.poly
Blueberry.aov = aov(Blueberry_pints_acre ~ NitrogenApp_lbs_acre,data = Q3)
summary(Blueberry.aov)
summary(Blueberry.aov,split = list(Blueberry_pints_acre=list(Linear=1,Quad=2,Cubic=3)))
#Load in the data from the experiment
worm = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 7/PinkBollwormData_update.csv",header = TRUE)
View(worm)
summary(worm.aov,split = list(DOY=list(Linear=1,Quad=2,Cubic=3)))
#Simple ANOVA with interaction w/ Type I SS
worm.aov = aov(Total_MothEmergence_per_acre ~ DOY * PlowDownTreatment, data = worm)
summary(worm.aov,split = list(DOY=list(Linear=1,Quad=2,Cubic=3)))
summary(worm.aov,split = list(DOY=list(Linear=1,Quad=2,Cubic=3)))
summary(Blueberry.aov,split = list(Blueberry_pints_acre=list(Linear=1,Quad=2,Cubic=3)))
summary(Blueberry.aov,split = list(NitrogenApp_lbs_acre=list(Linear=1,Quad=2,Cubic=3)))
summary(Blueberry.aov,split = list(NitrogenApp_lbs_acre=list(Linear=1,Quad=2,Cubic=3)))
summary(Blueberry.aov,split = list(NitrogenApp_lbs_acre=list(Linear=1,Quad=2,Cubic=3)))
#pairwise comparison of means
Blueberry.hsd = HSD.test(Blueberry.aov,"NitrogenApp_lbs_acre")
summary(Blueberry.aov,split = list(NitrogenApp_lbs_acre=list(Linear=1,Quad=2,Cubic=3)))
install_github("vqv/ggbiplot") #This will install ggbiplot
library(devtools)
library(ggfortify)
#library(ggbiplot)
library(remotes)
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
library(devtools)
install_github("vqv/ggbiplot") #This will install ggbiplot
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
library(ggbiplot)
#If you haven't updated R or your packages previously this will often fail repeatedly until all dependencies have been updated
#This sometimes requires restarting R because some packages that need to be updated are base packages
#If packages are already loaded you'll need to detach the packages first
install.packages("ggfortify") #ggfortify is another package that can create biplots using ggplot2, but it has less capabilities than ggbiplot
library(ggfortify)
install_github("vqv/ggbiplot") #This will install ggbiplot
install_github("vqv/ggbiplot") #This will install ggbiplot
install_github("vqv/ggbiplot") #This will install ggbiplot
install_github("vqv/ggbiplot") #This will install ggbiplot
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
View(model.quad)
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
#library(ggbiplot)
library(remotes)
library(ggfortify)
library(devtools)
library(ggbiplot)
install_github("vqv/ggbiplot") #This will install ggbiplot
updateR()
install.packages("installr")
library(installr)
updateR()
#Lab 9 Principal Component Analysis
#These are the packages that we will need
library(ggplot2)
#Lab 9 Principal Component Analysis
#These are the packages that we will need
install.packages("ggplot2")
library(ggplot2)
#library(ggbiplot)
library(remotes)
install.packages("remotes")
install.packages("ggfortify")
#library(ggbiplot)
library(remotes)
library(ggfortify)
#TO INSTALL GGBIPLOT --> ggbiplot makes quick clean biplots using ggplot2, but it can be buggy
#If you want to install ggbiplot you'll first need to install and load devtools
install.packages("devtools")
library(devtools)
library(devtools)
install_github("vqv/ggbiplot") #This will install ggbiplot
install.packages("rtools")
library(rtools)
install.packages("rtools")
library(ggfortify)
install_github("vqv/ggbiplot") #This will install ggbiplot
#Read in our extracellular enzyme data (EEA)
eea = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 9/NewMexicoEEA.csv",header = TRUE)
rm(list=ls())
#Read in our extracellular enzyme data (EEA)
eea = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 9/NewMexicoEEA.csv",header = TRUE)
library(ggfortify)
head(eea) #Take a look at the first 6 lines, we can see that there are missing values
eea$Depth = as.factor(eea$Depth)
eea = eea[complete.cases(eea),] #We cannot perform PCA with missing values
summary(eea) #We can confirm no missing values no our data.frame now
eea.pca = prcomp(eea[,11:17],scale. = TRUE,center = TRUE) #Runs PCA with prcomp
eea.pca #Displays the output from the PCA
summary(eea.pca) #Summary displays the explained variance for each PC and the cumulative variance across the PCs
screeplot(eea.pca) #Displays the screeplot for the PCA, which equates to a barplot of the explained variance as a function of the PCs
biplot(eea.pca) #Basic biplot produced using base graphics, this display is less useful
p = autoplot(eea.pca,data = eea,colour = "Depth",loadings = TRUE,loadings.label = TRUE,frame = T, frame.type = "norm",frame.level = 0.95) #Biplot based on ggplot2 using ggfortify package
p
eea.pca2 = princomp(eea[,11:17],cor = TRUE, scores = TRUE)
eea.pca2 = princomp(eea[,11:17],cor = TRUE, scores = TRUE)
#Displays the PC loadings, which can be used to interpret the meaning of the PCs
eea.pca2
eea.pca #Displays the output from the PCA
summary(eea.pca) #Summary displays the explained variance for each PC and the cumulative variance across the PCs
summary(eea.pca2)
plot(eea$PHOS.ln,eea.pca$x[,1])
p
Q1 = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Final/Question1_final.csv",header = TRUE)
Q2 = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Final/Question2_final.csv",header = TRUE)
Q3 = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Final/Question3_final.csv",header = TRUE)
Q4 = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Final/Question4_final.csv",header = TRUE)
View(Q1)
Fig1 = ggplot(data = Q1, aes(x=oc, y=al_ox)) + geom_point(size = 2) +
xlab("Organic Carbon") + ylab("Aluminum oxide") + ggtitle("Carbon vs Aluminum")
library(ggplot2)
library(ggplot2)
Fig1 = ggplot(data = Q1, aes(x=oc, y=al_ox)) + geom_point(size = 2) +
xlab("Organic Carbon") + ylab("Aluminum oxide") + ggtitle("Carbon vs Aluminum")
Fig1
cor(x = Q1$oc, y = Q1$al_ox, use = "everything", method =("pearson"))
model.lm = lm(al_ox ~ oc, data = Q1)
summary(model.lm)
rawdata = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 3/ProfileAveraged_SCM_Marshall_Gulch_Data.csv", header = TRUE)
#6 lines below create regression models that we will then be looking at
model.lm = lm(percentC ~ Ca, data = rawdata)
#Summary created below is to help determine which model to use
summary(model.lm)
anova(model.lm)
model.lm = lm(al_ox ~ oc, data = Q1) #Create a linear model to test for a linear relationship
linearmodel = lm(al_ox ~ oc, data = Q1) #Create a linear model to test for a linear relationship
summary(linear model)
summary(linear model)
summary(model.lm)
summary(linearmodel)
anova(linearmodel)
AIC(linearmodel) #A sort of index that indicates how closely the model matches the data that it was generated from. You want a lower value here
#6 lines below create regression models that we will then be looking at
model.lm = lm(percentC ~ Ca, data = rawdata)
#Summary created below is to help determine which model to use
summary(model.lm)
anova(model.lm)
#Creates a new scatter plot of all points for Ca and carbon
Fig1 = ggplot(data = rawdata, aes(x=Ca, y=percentC)) + geom_point(size = 2) +
xlab("Calcium") + ylab("Carbon%") + ggtitle("Calcium and carbon%")
Fig1
anova(linearmodel)
#Look at data graphically to see if we can immediately detect a positive relationship
Fig1 = ggplot(data = Q1, aes(x=oc, y=al_ox)) + geom_point(size = 2) +
xlab("Organic Carbon") + ylab("Aluminum oxide") + ggtitle("Carbon vs Aluminum")
Fig1
summary(linearmodel)
AIC(linearmodel) #A sort of index that indicates how closely the model matches the data that it was generated from. You want a lower value here
anova(linearmodel)
#Correlation test to let us have an idea about the correlation between the two factors. Indicates a slight positive relationship
cor(x = Q1$oc, y = Q1$al_ox, use = "everything", method =("pearson"))
summary(linearmodel)
View(Q2)
View(Q2)
contrasts(Q2$NitrogenApplication_lbs_per_acre) = contr.poly
#Question 2
Q2$NitrogenApplication_lbs_per_acre=as.factor(Q2$NitrogenApplication_lbs_per_acre)
Q2$Irrigation = as.factor(Q2$Irrigation)
contrasts(Q2$NitrogenApplication_lbs_per_acre) = contr.poly
#Load in the data from the experiment
worm = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 7/PinkBollwormData_update.csv",header = TRUE)
worm$PlowDownTreatment=as.factor(worm$PlowDownTreatment)
worm$DOY = as.factor(worm$DOY)
contrasts(worm$DOY) = contr.poly #This tells R we want to use orthoganol polynomial contrasts
#Interaction plot of responses and factors
interaction.plot(x.factor = worm$DOY, trace.factor = worm$PlowDownTreatment, response = worm$Total_MothEmergence_per_acre,type = "b",pch=c(15,16,17,18),fixed = TRUE)
library(agricolae)
#Levene's Test for homogeneous variances
leveneTest(Corn_Yields_bushel_per_acre~NitrogenApplication_lbs_per_acre * Irrigation, data = Q2)
library(car)
#Levene's Test for homogeneous variances
leveneTest(Corn_Yields_bushel_per_acre~NitrogenApplication_lbs_per_acre * Irrigation, data = Q2)
#Shapiro's test for normality of responses
shapiro.test(worm$Total_MothEmergence_per_acre)
Q2.aov = aov(Corn_Yields_bushel_per_acre ~ NitrogenApplication_lbs_per_acre * Irrigation, data = Q2)
summary(worm.aov)
summary(Q2.aov)
hist(resid(Q2.aov)) #Histogram of our model residuals
shapiro.test(resid(Q2.aov)) #Normality test of residuals
Q2.lsd = LSD.test(Q2.aov,"Treatment")
Q2.lsd
Q2.lsd
Q2.lsd = LSD.test(Q2.aov,"Treatment")
Q2.lsd
Q2.lsd = LSD.test(Q2.aov)
#Adds our beet dataset
beets = read.csv(file = "D:/Grad School/Courses/Spring 2021/PLS 697/Module 5/Lab5BeetTrial.csv",header = TRUE)
View(beets)
View(beets)
Q2.lsd = LSD.test(Q2.aov,"Irrigation")
Q2.lsd
Q2.lsd.irrigation
Q2.lsd.irrigation = LSD.test(Q2.aov,"Irrigation")
Q2.lsd.irrigation
Q2.lsd.fertilizer = LSD.test(Q2.aov,"NitrogenApplication_lbs_per_acre")
Q2.lsd.fertilizer
Q2.lsd.irrigation = LSD.test(Q2.aov, trt = c("NitrogenApplication_lbs_per_acre","Irrigation"))
Q2.lsd.irrigation
install.packages("pwr")
citation(package = "pwr")
citation()
setwd("D:/GitHub/Code-Club/Data Analysis/Mothur/Alpha Diversity Bar Graph") #Change to your working directory where files are stored
dataset <- read_tsv(file="Alpha diversity.summary", col_types = cols(group=col_character())) #Read in your nmds file
library(readxl)
dataset <- read_tsv(file="Alpha diversity.summary", col_types = cols(group=col_character())) #Read in your nmds file
library(tidyverse)
dataset <- read_tsv(file="Alpha diversity.summary", col_types = cols(group=col_character())) #Read in your nmds file
View(dataset)
#Inverse Simpson alpha diversity
InvSimpplot = ggplot(data = dataset, aes(x= group, y=invsimpson)) +
geom_bar(stat="identity")
InvSimpplot
#Shannon alpha diversity
Shannonplot = ggplot(data = dataset, aes(x= group, y=Shannon)) +
geom_bar(stat="identity")
Shannonplot
#Shannon alpha diversity
Shannonplot = ggplot(data = dataset, aes(x= group, y=shannon)) +
geom_bar(stat="identity")
Shannonplot
